## Итоги

В процессе работы было сделано следующее:
1. **Проведен разведочный анализ данных**. 

В процессе его проведения была изучена структура тренировочного и тестового набора данных.
Были обработаны пропуски: для вещественных признаков взяли медианное значение, для категориальных - наиболее часто встречающееся.
Также были удалены повторяющиеся строки, с оставлением первой строки по автомобилю, когда цены отличаются при повторяющемся признаковом описании.
Были преобразованы некоторые признаки: из значений убраны единицы измерения, удалены лишние признаки, некоторые признаки приведены в нужному типу данных.
После проведения всех преобразований мы увидели, что значиельных сдвигов в первоначальные распределения тренировочного и 
тестового наборов данных мы не внесли.

Нами были построены основные визуаизации для оценки распределений и корреляций признаков. Анализ этих визуализаций показал,
что совокупности данных выглядят очень похожими - в них наблюдаются практически одинаковые корреляции. Благодаря этому убедились, что данные
были разделены качественно. Также мы проанализировали распределение целевой переменной (цены продажи автомобиля), благодаря чему был сделан важный вывод -
в целевой переменной имеется сильная положительная асимметрия, значит, её можно будет прологарифмировать для снижения влияния 
выборосов и улучшения результатов прогнозов.

2. **Построили модели линейной регрессии только на вещественных признаках.**

Изначально в своём классическом варианте модель линейной регрессии продемонстрировала среднее качество предсказаний и отсутствие переобучения.
Далее была сделана попытка улучшить модель с помощью стандартизации значений признаков. В результате качество модели не изменилось, но
мы получили возможность интепретации признаков модели, увидели какие признаки являются наиболее информативными (в нашем случае - признак max_power).

Далее мы пробовали улучшать результаты с помощью регуляризации: была опробована Lasso-регрессия с подбором гиперпараметров через GridSearch.
При этом качество модели чуть упало.
Ситуацию не улучшила и ElasticNet-регрессия с GridSearch - в лучшей отобранной модели качество упало ещё ниже.

3. **Построили модели с добавлением категориальных признаков.**

В данные для обучения были добавлены категориальные признаки, столбец name был обработан и подготовлен к OneHot-кодированию - оставлена только марка авто, 
уменьшено число потенциальных категорий с помощью задания порогово значения частоты марки в наборе данных, ниже которого в name записывалась категория "other".
Количественные признаки были стандартизированы с помощью MinMaxScaler, категориальные - закодированы с помощью OneHot-кодирования.
Затем была построена модель ridge-регрессии с подбором гиперпараметров. Все эти действия дали значительный прирост качества работы модели, но увеличили переобучение.
Тогда мы попробовали перед обучением логарифмировать целевую переменную, как планировали ранее, и получили еще более сильный прирост качества со 
значительным уменьшением переобучения. Поэтому для результатов этой модели проводится их экспоненцииование для возвращения 
исходной размерности целевой переменной (это же делается и в сервисе).

4. **Разработали бизнес-метрику для оценки качества модели бизнесом.**

Метрика получилась простой и понятной бизнесу, она позволяет наглядно сравнить качество различных вариантов линейных моделей.

5. **Написали сервис на FastAPI.**

Сервис реализует функциональость предсказания цены автомобиля для одного объекта и для нескольких объектов 
(объекты также могут передаваться в формате csv-файла). Сервис реализован на основе нашей самой качественной модели - 
ridge-регрессии с закодированными категориальными признаками, стандартизрованными количественными признаками, 
и с логарифмиованной целевой переменной. Развертывание сервиса реализовано через docker-compose.

